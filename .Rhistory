6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
squamate_lossgain_2r<-fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn")
## fit loss/gain multi-rate model
D<-matrix(c(
0,6,0,0,0,0,
1,0,7,0,0,0,
0,2,0,8,0,0,
0,0,3,0,9,0,
0,0,0,4,0,10,
0,0,0,0,5,0),
6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
squamate_lossgain_10r<-fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn")
## fit loss/gain + jump model
D<-matrix(c(
0,7,0,0,0,0,
1,0,8,0,0,0,
6,2,0,9,0,0,
6,0,3,0,10,0,
6,0,0,4,0,11,
6,0,0,0,5,0),
6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
squamate_lossgain_jump<-fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn")
## compare among all fitted models (sorted by complexity)
anova(
squamate_er,
squamate_lossonly_1r,
squamate_lossgain_2r,
squamate_lossonly_5r,
squamate_lossonly_jump,
squamate_lossgain_10r,
squamate_lossgain_jump)
## from this we see evidence that we FAILED to converge to the
## true MLEs for our two most complex models. Why do I think that?
## let's run multiple optimization iterations in parallel
## load required packages
library(foreach)
library(doParallel)
niter<-30 ## number of iterations
ncores<-min(niter,detectCores()-4) ## number of cores (leave 4 free)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
## loss/gain multi-rate model design matrix
D<-matrix(c(
0,6,0,0,0,0,
1,0,7,0,0,0,
0,2,0,8,0,0,
0,0,3,0,9,0,
0,0,0,4,0,10,
0,0,0,0,5,0),
6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
lossgain10r_fits<-foreach(i=1:niter)%dopar%{
phytools::fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn",rand_start=TRUE,
lik.func="lik",logscale=sample(c(TRUE,FALSE),1))
}
## get log-likelihoods
lnL<-sapply(lossgain10r_fits,logLik)
lnL
## new best model
squamate_lossgain_10r<-lossgain10r_fits[[which.max(lnL)]]
## loss/gain + jump design matrix
D<-matrix(c(
0,7,0,0,0,0,
1,0,8,0,0,0,
6,2,0,9,0,0,
6,0,3,0,10,0,
6,0,0,4,0,11,
6,0,0,0,5,0),
6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
lossgainjump_fits<-foreach(i=1:niter)%dopar%{
phytools::fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn",rand_start=TRUE,
lik.func="lik",logscale=sample(c(TRUE,FALSE),1))
}
## get log-likelihoods
lnL<-sapply(lossgainjump_fits,logLik)
lnL
## new best model
squamate_lossgain_jump<-lossgainjump_fits[[which.max(lnL)]]
## stop cluster
stopCluster(cl=mc)
## re-run comparison
anova(
squamate_er,
squamate_lossonly_1r,
squamate_lossgain_2r,
squamate_lossonly_5r,
squamate_lossonly_jump,
squamate_lossgain_10r,
squamate_lossgain_jump)
squamate_lossgain_jump
squamate_lossgain_10r
niter<-30 ## number of iterations
ncores<-min(niter,detectCores()-4) ## number of cores (leave 4 free)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
lossgainjump_fits<-foreach(i=1:niter)%dopar%{
phytools::fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn",rand_start=TRUE,
lik.func="lik",logscale=FALSE) #sample(c(TRUE,FALSE),1))
}
## get log-likelihoods
lnL<-sapply(lossgainjump_fits,logLik)
lnL
## new best model
squamate_lossgain_jump<-lossgainjump_fits[[which.max(lnL)]]
## stop cluster
stopCluster(cl=mc)
## re-run comparison
anova(
squamate_er,
squamate_lossonly_1r,
squamate_lossgain_2r,
squamate_lossonly_5r,
squamate_lossonly_jump,
squamate_lossgain_10r,
squamate_lossgain_jump)
squamate_lossgain_jump
lnL
niter<-30 ## number of iterations
ncores<-min(niter,detectCores()-4) ## number of cores (leave 4 free)
mc<-makeCluster(ncores,type="PSOCK")
registerDoParallel(cl=mc)
## loss/gain + jump design matrix
D<-matrix(c(
0,7,0,0,0,0,
1,0,8,0,0,0,
6,2,0,9,0,0,
6,0,3,0,10,0,
6,0,0,4,0,11,
6,0,0,0,5,0),
6,6,byrow=TRUE,
dimnames=list(0:5,0:5))
lossgainjump_fits<-foreach(i=1:niter)%dopar%{
phytools::fitMk(squamate_tree,hind_digits,
model=D,pi="fitzjohn",rand_start=TRUE,
lik.func="lik",logscale=TRUE)
}
## get log-likelihoods
lnL<-sapply(lossgainjump_fits,logLik)
lnL
## new best model
squamate_lossgain_jump<-lossgainjump_fits[[which.max(lnL)]]
## stop cluster
stopCluster(cl=mc)
## re-run comparison
anova(
squamate_er,
squamate_lossonly_1r,
squamate_lossgain_2r,
squamate_lossonly_5r,
squamate_lossonly_jump,
squamate_lossgain_10r,
squamate_lossgain_jump)
lnL
save.image("C:/Users/liamj/Dropbox/courses/BIOL634-fall2025/hw/4/hw4-solution.RData")
library(geiger)
tree<-pbtree(n=10)
x<-sim.char(tree)
x<-sim.char(tree,par=list(sigma=0.5))
x<-sim.char(tree,par=0.5)
x
?sim.char
?rTraitCont
?fastBM
?fastBM
tree<-pbtree(n=100,scale=1)
x<-fastBM(tree,alpha=1)
x<-fastBM(tree,alpha=1,theta=0)
geiger::fitContinuous(tree,x)
geiger::fitContinuous(tree,x,model="OU")
?rTraitCont
?fastBM
tree<-pbtree(n=500,scale=1)
x<-fastBM(tree,alpha=1,theta=0)
geiger::fitContinuous(tree,x,model="OU")
?rTraitCont
?fastBM
tree<-pbtree(n=1000,scale=1)
x<-fastBM(tree,alpha=0.5,theta=0)
geiger::fitContinuous(tree,x,model="OU")
?rTraitCont
?fastBM
tree<-pbtree(n=2000,scale=1)
x<-fastBM(tree,alpha=0.5,theta=0)
geiger::fitContinuous(tree,x,model="OU")
?rTraitCont
?fastBM
tree<-pbtree(n=2000,scale=1)
x<-fastBM(tree,alpha=0.8,theta=0)
geiger::fitContinuous(tree,x,model="OU")
?rTraitCont
?fastBM
tree<-pbtree(n=5000,scale=1)
x<-fastBM(tree,alpha=0.8,theta=0)
geiger::fitContinuous(tree,x,model="OU")
tree<-pbtree(N=100,b=1,d=0.3)
tree<-pbtree(n=100,b=1,d=0.3)
tree
library(phangorn)
howmanytrees()
howmanytrees(10)
howmanytrees(20)
?howmanytrees
phangorn::howmanytrees(n=15)
## load packages
library(phytools)
library(geiger)
## load some data
data("cordylid.tree")
## plot this tree
plotTree(cordylid.tree,ftype="i")
## plot this tree
plotTree(cordylid.tree,ftype="i",fsize=0.9)
args(nodelabels)
nodelabels(cex=0.6,frame="circle",bg="white")
## load in my data
data("cordylid.data")
head(cordylid.data)
##
cordylid_armoring<-setNames(cordylid.data$pPC1,
rownames(cordylid.data))
cordylid_armoring
## estimate ML ancestral states using fastAnc
cordylid_ml<-fastAnc(cordylid.tree,cordylid_armoring)
cordylid_ml
## estimate ML ancestral states using fastAnc
cordylid_ml<-fastAnc(cordylid.tree,cordylid_armoring,
CI=TRUE)
cordylid_ml
## compare 95% CI on root to range of trait
range(cordylid_armoring)
## visualize our reconstruction using contMap
cordylid_cmap<-contMap(cordylid.tree,cordylid_armoring,
plot=FALSE)
cordylid_cmap
plot(cordylid_cmap)
plot(cordylid_cmap,fsize=0.8)
## update our color gradient
cordylid_cmap<-setMap(cordylid_cmap,hcl.colors(n=100))
plot(cordylid_cmap,fsize=0.8)
nodelabels(cex=0.6,frame="circle",bg="white")
## let's Bayesian MCMC ancestral state reconstruction
cordylid_mcmc<-anc.Bayes(cordylid.tree,
cordylid_armoring,ngen=500000)
anc.Bayes
## informative prior on the root
Prior_mean<-c(1000,min(cordylid_armoring),
rep(mean(cordylid_armoring,cordylid.tree$Nnode)))
Prior_mean
## informative prior on the root
Prior_mean<-c(1000,min(cordylid_armoring),
rep(mean(cordylid_armoring),cordylid.tree$Nnode))
Prior_mean
var(cordylid_armoring)
Prior_var<-c(1e6,0.25,rep(1000,cordylid.tree$Nnode-1))
cordylid_mcmc.informative<-anc.Bayes(cordylid.tree,
cordylid_armoring,ngen=500000,
control=list(pr.mean=Prior_mean,pr.var=Prior_var))
cordylid_mcmc.informative$ace
cordylid_mcmc.informative
Prior_var<-c(1e6,0.01,rep(1000,cordylid.tree$Nnode-1))
cordylid_mcmc.informative<-anc.Bayes(cordylid.tree,
cordylid_armoring,ngen=500000,
control=list(pr.mean=Prior_mean,pr.var=Prior_var))
cordylid_mcmc.informative
cordyld_mcmc
cordylid_mcmc
dev.off()
cordylid_ml
str(cordylid_mcmc)
obj<-print(cordylid_mcmc)
str(obj)
plot(cordylid_ml$ace,obj)
plot(cordylid_ml$ace,obj,bty="n",pch=21,pt.bg="grey",
xlab="ML estimates",ylab="Bayesian estimates")
plot(cordylid_ml$ace,obj,bty="n",pch=21,bg="grey",
xlab="ML estimates",ylab="Bayesian estimates")
plot(cordylid_ml$ace,obj,bty="n",pch=21,bg="grey",
xlab="ML estimates",ylab="Bayesian estimates",
las=1)
grid()
min(cordylid_armoring)
cordylid.tree$Nnode
## let's specify an informative prior
Prior_mean<-c(
1000,
min(cordylid_armoring),
rep(mean(cordylid_armoring),cordylid.tree$Nnode-1))
var(cordylid_armoring)
Prior_var<-c(
1e6,
0.01,
rep(1000,cordylid.tree$Nnode-1))
cordylid_mcmc.informative<-anc.Bayes(cordylid.tree,
cordylid_armoring,ngen=500000,
control=list(pr.mean=Prior_mean,
pr.var=Prior_var))
cordylid_mcmc.informative
obj<-print(cordylid_mcmc.informative)
plot(cordylid_ml$ace,obj,bty="n",pch=21,bg="grey",
xlab="ML estimates",ylab="Bayesian estimates (informative prior)",
las=1)
grid()
cordylid_cmap.bayes<-contMap(cordylid_tree,
cordylid_armoring,anc.states=obj$ace,plot=FALSE)
cordylid_cmap.bayes<-contMap(cordylid.tree,
cordylid_armoring,anc.states=obj$ace,plot=FALSE)
cordylid_cmap.bayes<-contMap(cordylid.tree,
cordylid_armoring,anc.states=obj$ace,plot=FALSE)
cordylid_cmap.bayes<-setMap(cordylid_cmap.bayes,
hcl.colors(n=100))
plot(cordylid_cmap.bayes,fsize=0.8)
cordylid_cmap.bayes<-contMap(cordylid.tree,
cordylid_armoring,anc.states=obj,plot=FALSE)
cordylid_cmap.bayes<-setMap(cordylid_cmap.bayes,
hcl.colors(n=100))
plot(cordylid_cmap.bayes,fsize=0.8)
dev.off()
obj<-print(cordylid_mcmc.informative)
plot(cordylid_ml$ace,obj,bty="n",pch=21,bg="grey",
xlab="ML estimates",ylab="Bayesian estimates (informative prior)",
las=1)
grid()
cordylid_cmap.bayes<-contMap(cordylid.tree,
cordylid_armoring,anc.states=obj,plot=FALSE)
cordylid_cmap.bayes<-setMap(cordylid_cmap.bayes,
hcl.colors(n=100))
plot(cordylid_cmap.bayes,fsize=0.8)
cordylid_cmap.bayes<-contMap(cordylid.tree,
cordylid_armoring,method="user",
anc.states=obj,plot=FALSE)
cordylid_cmap.bayes<-setMap(cordylid_cmap.bayes,
hcl.colors(n=100))
plot(cordylid_cmap.bayes,fsize=0.8)
plot(cordylid_cmap,ftype="off")
par(mfrow=c(1,2))
plot(cordylid_cmap,ftype="off")
plot(cordylid_cmap.bayes,ftype="off",
direction="leftwards")
plot(cordylid_cmap,ftype="off",fsize=0.6)
plot(cordylid_cmap.bayes,ftype="off",
direction="leftwards",fsize=0.6)
dev.off()
plot(cordylid_cmap.bayes,ftype="off",
direction="leftwards",fsize=0.6)
plot(cordylid_cmap.bayes,ftype="off",
direction="rightwards",fsize=0.6)
nodelabels(frame="circle",cex=0.6)
cordylid_node.42<-density(cordylid_mcmc.informative,what=42)
dev.off()
plot(cordylid_node.42)
cordylid_node.42
## load primate data
data(primate.tree)
data(primate.data)
## pull out our character
activity<-setNames(primate.data$Activity_pattern,
rownames(primate.data))
activity
## fit three models: ER, SYM, ARD models
er_primates<-fitMk(primate.tree,activity,
model="ER")
sym_primates<-fitMk(primate.tree,activity,
model="SYM")
ard_primates<-fitMk(primate.tree,activity,
model="ARD")
## traditionally, we would compare these three
## models and choose the "best"
anova(er_primates,
sym_primates,
ard_primates)
## estimate marginal ancestral states under
## "best" (i.e., ER) model
primate_er.marginal<-ancr(er_primates)
primate_er.marginal
## we can plot this
plot(primate_er.marginal)
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("yellow","pink","purple")))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("pink","yellow","purple")))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("pink","yellow","navy")))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("pink","gold","navy")))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards",type="fan"),
args.nodelabels=list(piecol=c("pink","gold","navy")))
## we can plot this
plot(primate_er.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("pink","gold","navy")))
## re-calculate our model comparison
anova(er_primates,
sym_primates,
ard_primates)->aov_primates
aov_primates
primate_modelaveraged.marginal<-ancr(aov_primates)
primate_modelaveraged.marginal
plot(primate_modelaveraged.marginal,
args.plotTree=list(direction="upwards"),
args.nodelabels=list(piecol=c("pink","gold","navy")))
getwd("courses/Israel-2025/work/")
setwd("courses/Israel-2025/work/")
## load dataset and tree
download.file(
url="https://liamrevell.github.io/hula2025/data/Liolaemidae.data.csv",
destfile="Liolaemidae.data.csv")
download.file(
url="https://liamrevell.github.io/hula2025/data/Liolaemidae.MCC.nex",
destfile="Liolaemidae.MCC.nex")
## load packages
library(phytools)
## read in the data from file.
liol_data<-read.csv(file="Liolaemidae.data.csv",
row.names=1)
head(liol_data)
## read in the data from file.
liol_data<-read.csv(file="Liolaemidae.data.csv",
row.names=1,stringsAsFactors=TRUE)
head(liol_data)
liol_data$parity_mode
## read the tree from file
liol_tree<-read.nexus(file="Liolaemidae.MCC.nex")
liol_tree
plotTree(liol_tree,type="arc",fsize=0.5,lwd=1,
arc_height=0.2)
plotTree(liol_tree,type="arc",fsize=0.5,lwd=1,
arc_height=0.2,part=1)
plotTree(liol_tree,type="arc",fsize=0.3,lwd=1,
arc_height=0.2,part=1)
plotTree(liol_tree,type="arc",fsize=0.3,lwd=1,
arc_height=0.2,part=0.8)
plotTree(liol_tree,type="arc",fsize=0.3,lwd=1,
arc_height=0.2,part=0.95)
plotTree(liol_tree,type="arc",fsize=0.3,lwd=1,
arc_height=0.2,part=0.95,ftype="i")
## start by fitting our Mk models
liol_parity_er<-fitMk(liol_tree,parity,
model="ER",pi="fitzjohn")
## let's pull out parity mode
parity<-setNames(liol_data$parity_mode,
rownames(liol_data))
head(parity)
name.check(liol_tree,liol_data)
geiger::name.check(liol_tree,liol_data)
## start by fitting our Mk models
liol_parity_er<-fitMk(liol_tree,parity,
model="ER",pi="fitzjohn")
liol_parity_er
liol_parity_ard<-fitMk(liol_tree,parity,
model="ARD",pi="fitzjohn")
liol_parity_ard
## now let's fit the threshold model
?fitThresh
liol_parity_thresh<-fitThresh(liol_tree,
parity)
liol_data$parity_mode
attach(liol_data)
parity
head(liol_data)
parity_mode
detach(liol_data)
liol_parity_thresh
logLik(liol_parity_thresh)
## let's compare our three models so far
anova(liol_parity_er,liol_parity_ard,
liol_parity_thresh)
## let's fit a hidden-rate model
?fitHRM
liol_parity_hrm<-fitHRM(liol_tree,parity,ncat=2,
pi="fitzjohn",parallel=TRUE)
liol_parity_hrm
plot(liol_parity_hrm)
## let's compare our four models!
anova(liol_parity_er,liol_parity_ard,
liol_parity_thresh,liol_parity_hrm)
##
?fitcontMk
head(liol_data)
liol_temp<-setNames(liol_data$temperature,
rownames(liol_data))
liol_cont_disc<-fitcontMk(liol_tree,
parity,liol_temp,parallel=TRUE,ncores=10,
levs=50,maxit=5000)
liol_cont_disc
plot(liol_cont_disc)
getwd()
setwd("../hula2025/")
list.files("ex")
git status
